{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5deb1034",
   "metadata": {},
   "source": [
    "## Partie 1 Construction du CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbcd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers.convolutional import MaxPooling2D\n",
    "    from keras.layers import Flatten\n",
    "    \n",
    "    from keras.layers import Dropout\n",
    "    \n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee776101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le CNN\n",
    "    classifier = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875310ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 1 : Convolution \n",
    "    classifier.add(Conv2D(filters = 32, \n",
    "                          kernel_size = [6,6], \n",
    "                          strides= 1, \n",
    "                          input_shape=(64,64,3), \n",
    "                          activation=\"relu\")) # relu = fct redresseur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 2 : Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size=(4,4), \n",
    "                                strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafae8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'une couche de convolution (+pooling) pour éviter le sur entrainement \n",
    "    classifier.add(Conv2D(filters = 32, \n",
    "                          strides= 1,\n",
    "                          kernel_size = [6,6], # A voir\n",
    "                          activation=\"relu\")) \n",
    "    classifier.add(MaxPooling2D(pool_size=(4,4), \n",
    "                                strides=2))\n",
    "    \n",
    "    classifier.add(Conv2D(filters = 32, \n",
    "                          strides= 1,\n",
    "                          kernel_size = [6,6], # A voir\n",
    "                          activation=\"relu\")) \n",
    "    classifier.add(MaxPooling2D(pool_size=(4,4), \n",
    "                                strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 3 : Flattening\n",
    "    classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4844dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 4 : Réseau Neuronne\n",
    "    classifier.add(Dense(units=128, activation= \"relu\", kernel_initializer=\"uniform\"))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    \n",
    "    classifier.add(Dense(units=128, activation= \"relu\", kernel_initializer=\"uniform\"))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    \n",
    "    classifier.add(Dense(units=1, activation= \"sigmoid\"))  # sortie 1 ou 0 si plus : \"softmax\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 6 : Entrainer les images\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                                shear_range=0.2,\n",
    "                                                zoom_range=0.2,\n",
    "                                                horizontal_flip=True)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    \n",
    "    training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                     target_size=(64, 64),\n",
    "                                                     batch_size=16,\n",
    "                                                     class_mode='binary')\n",
    "    \n",
    "    test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=16,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "    classifier.fit(training_set,\n",
    "                   steps_per_epoch=500,  #8000/32\n",
    "                   epochs=30,\n",
    "                   validation_data= test_set,\n",
    "                   validation_steps=125,  #2000/32\n",
    "                   #use_multiprocessing=True,\n",
    "                   #verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "                   callbacks=[tensorboard_callback])\n",
    "    \n",
    "    classifier.save()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3866f80",
   "metadata": {},
   "source": [
    "## Etape 2 : Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "test_image = keras.utils.load_img(\"dataset/test_set/dogs/dog.4023.jpg\", \n",
    "                                  target_size = (64,64))\n",
    "\n",
    "test_image = keras.utils.img_to_array(test_image)\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = classifier(test_image)\n",
    "\n",
    "training_set.class_indices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
