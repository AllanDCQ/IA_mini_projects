{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8789a03",
   "metadata": {},
   "source": [
    "# Reccurent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c382e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d004c",
   "metadata": {},
   "source": [
    "## Partie 1 - Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Jeu d'entrainement \"\"\"\n",
    "    \n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "    \n",
    "training_set = dataset_train[[\"Open\"]].values  #selectionne la colonne open et le transforme en array\n",
    "    \n",
    "    \n",
    "\"\"\" Mise à l'échelle \"\"\"\n",
    "    # Mettre à l'échelle : Standardise(-1/1) ou Normalise(0/1)\n",
    "    # Pour les recurrent, normaisation surtout pour sigmoid en entrée\n",
    "    \n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "    \n",
    "\"\"\" Création de la structure avec 60 timesteps et 1 sortie\"\"\"\n",
    "    # Il va regardé les 60 jours précédents et prédire le prochain jour\n",
    "    \n",
    "x_train = []  # liste des 60 jours précédent y\n",
    "y_train = []  # jour de prédiction \n",
    "    \n",
    "for i in range(60,1258) :\n",
    "    x_train.append(training_set_scaled[(i-60):i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "\"\"\" Tableau en 3 Dimensions \"\"\"\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))  # 2 si on veut rajouter des autres données ex : action du dollar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750c2a1",
   "metadata": {},
   "source": [
    "## Partie 2 - Création du RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a14f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "\"\"\" 1ere couche \"\"\"\n",
    "regressor.add(LSTM(units=50, return_sequences=True,  #return_sequences = pour avoir plusieurs couches de LSTM\n",
    "                       input_shape=(x_train.shape[1], 1) ))\n",
    "regressor.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    \n",
    "\"\"\" 2e couche \"\"\"\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(rate = 0.2))\n",
    "\n",
    "    \n",
    "\"\"\" 3e couche \"\"\"\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(rate = 0.2))\n",
    "\n",
    "\"\"\" 4e couche \"\"\"\n",
    "regressor.add(LSTM(units=50, return_sequences=False))\n",
    "regressor.add(Dropout(rate = 0.2))\n",
    "\n",
    "\"\"\" Couche de sortie \"\"\"\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Compile \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Entrainement \"\"\"\n",
    "regressor.fit(x_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b94f4",
   "metadata": {},
   "source": [
    "## Parite 3 - Prédictions et vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42517c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donnees 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Prediction 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "x_test = []\n",
    "for i in range(60, 80):\n",
    "    x_test.append(inputs[i-60:i, 0])\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(x_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualisation des resultats\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
